
= APLで受付システムを作ってみよう！

//image[tag][]{
//}

//flushright{
著者：がおまる（@<href>{https://twitter.com/gaomar/,@gaomar}）
//}

== はじめに
2019年から様々なEchoデバイスの画面付きスマートディスプレイが登場してきました。この章では、APLを使って画面付きデバイス対応スキルを作っていきます。

===== 本章の対象読者@<br>{}

本章の対象読者は、次のような方です。  

 * Alexaスキルの開発経験がある開発者向け(ノンコーティングは除く)

===== 本章の前提知識@<br>{}

本章を読み進めるにあたり、次の基礎知識が必要です。  

 * Alexaスキル開発に求められる技術全般

===== 本章の必要環境@<br>{}

本章を読み進めるにあたり、次の環境が必要です。  

 * Node.js（※ v10.16.3 推奨）
 * Git
 * Visual Studio Code

//blankline

日本国内で購入できる、スマートディスプレイに対応しているラインナップをおさらいしましょう。

 * Echo Show 5
 * Echo Show
 * Echo Spot（※2019年12月現在 取り扱い終了）

その他にもFireタブレットシリーズがあります。

 * Fire HD 10
 * Fire HD 8
 * Fire HD 7

== APLとは？


APLとは @<tt>{Alexa Presentation Language} の略称です。画面付きスマートディスプレイのスキルに対して視覚エクスペリエンスを作成できます。
ホームページを作成するときの @<tt>{CSS} と似たようなものと思っていただけると良いかもしれません。@<br>{}
基本的にデータ構造とドキュメント構造があります。簡易的なアニメーションや、画面をタップしたときの処理を行うコマンドなどもあります。


== アーキテクチャ


今回作る受付システムのアーキテクチャです。Azure Functionsを使ってローカル環境で動かせるようにしています。
もちろんそのままAzureにデプロイすることも可能です。おまけ要素に来客が来たことをLINEに通知させる部分も行います。



//image[s000][受付システムのアーキテクチャ]{
//}



== 環境構築


各準備を行っていきます。必要なものは以下の通りです。

 * 新規プロジェクト作成
 * APL作成
 * Azure Functions ローカル環境設定
 * 動作確認
 * おまけ - LINE Notify通知



それでは順番に用意していきます。


=== 新規プロジェクト作成

==== 新規プロジェクトを作成する


新規プロジェクトを作成しましょう。下記URLにアクセスしてください。


//emlist{
https://developer.amazon.com/ja-JP/alexa/alexa-skills-kit
//}



［スキル開発を始める］をクリックします。



//image[s100][スキル開発を始める]{
//}




お持ちのAmazonアカウントでログインして、［スキルの作成］ボタンをクリックします。



//image[s101][スキルの作成ボタンをクリック]{
//}




スキル名は「受付システム」と入力し、［スキルを作成］ボタンをクリックします。この画面には表示されていませんが、「スキルに追加するモデルを選択」カテゴリは @<tt>{カスタム} を、
「スキルのバックエンドリソースをホスティングする方法を選択」カテゴリは @<tt>{ユーザー定義のプロビジョニング} を選択します。



//image[s102][スキルを作成ボタンをクリック]{
//}



==== 呼び出し名の設定


呼び出し名を設定します。左側メニューから呼び出し名をクリックします。スキルの呼び出し名に「受付システム」と入力します。必ず［モデルを保存］をしてください。



//image[s103][呼び出し名の設定]{
//}

正しく保存されると画面右下に「対話モデルは正常に保存されました」と表示されます。

//image[s103-1][正しく保存されたことを確認する]{
//}


==== インターフェースの設定


画面付きスマートディスプレイの設定を行います。「Displayインターフェース」と「Alexa Presentation Language」の 2箇所をチェックしてください。



//image[s104][インターフェースの設定]{
//}



=== インテントの設定


ある言葉に反応させるためのインテント（意図）を設定します。会社名で反応するためのインテントを作成します。
ダイアログデリゲートという機能を使って、会社名、お名前、人数を答えてもらいその情報を取得します。


==== インテントを作成する


左側のインテント部分の［＋追加］ボタンをクリックし、@<tt>{StartIntent} と入力します。入力したら［カスタムインテントを作成］ボタンをクリックします。



//image[s105][StartIntentと入力する]{
//}



==== インテントスロットの設定


画面が切り替わったら画面を下までスクロールして、ダイアログデリゲートのルールにあるインテントスロットの設定を行います。名前部分に @<tt>{company_val} と入力して右側にある［＋］ボタンをクリックします。スロットタイプは @<tt>{AMAZON.Corporation} を選択して、［ダイアログを編集］をクリックします。



//image[s106][company_valのインテントスロット設定]{
//}



==== ダイアログ編集


スロット入力を必須にしますので、有効にしてください。Alexaの音声プロンプト部分に「会社名をお答えください」と入力し、［Enter］キーで確定してください。ユーザーの発話部分に「○○です」など、考えられる言葉を登録します。
ここでは先程定義した 「{company_val} です」、「会社名は {company_val} 」、「{company_val} と申します」というように入力します。


//image[s107][ダイアログ編集]{
//}




［モデルを保存］ボタンをクリックし、 @<tt>{StartIntent} 部分をクリックします。



//image[s108][StartIntentをクリック]{
//}



==== その他インテントスロット設定


他にも来訪者の名前を取得するためのスロットや来訪者人数などを格納するためのスロットを用意します。インテントスロットをまとめると下記のようになります。



//image[s110][インテントスロット]{
//}




//image[s109][インテントスロット設定例]{
//}



==== その他ダイアログ編集


来訪者の名前と人数を取得するときにAlexaが発話する内容を設定します。インテントスロットにある［ダイアログを編集］をそれぞれクリックして編集します。@<br>{}
会社名で取得したときと同様にスロット入力を必須にしてください。それぞれの設定は下記のようにしました。



//image[s111][ダイアログ編集設定]{
//}



==== サンプル発話を登録


APLで画面をタップして、会社名を言ってもらったときに反応するサンプル発話を登録しておきます。［モデルを保存］と［モデルをビルド］ボタンを順番にクリックします。
ビルドは2〜3分ほどかかります。


//image[s112][サンプル発話を登録する]{
//}

保存した際に「発話の競合を検出しました」と警告メッセージが表示されますが、無視して構いません。

//image[s112-1][無視して構いません]{
//}




=== APL作成


スマートディスプレイ画面に表示するAPLファイルを作成しましょう。APLはドキュメント構造とデータ構造に分かれております。まずは、ドキュメント構造を見ていきます。


==== ドキュメント構造作成


左側のメニューに［画面表示］という項目があるのでクリックします。
//image[s200][画面表示をクリック]{
//}




別の画面が表示されますので、［テンプレートを作成］ボタンをクリックします。



//image[s201][テンプレートを作成をクリック]{
//}




スキルの表示方法を選択する画面が表示されるので、［最初から作成］をクリックします。



//image[s202][最初から作成をクリック]{
//}




左側メニューの @<tt>{APL} をクリックして、下記URLのJSONファイルを貼り付けてみてください。プレビュー画面に反映されて、APLがどのように表示されるか各デバイス毎に確認することができます。



JSONファイルURL@<br>{}


//emlist{
http://bit.ly/apl_top_json
//}



//image[s203][ドキュメント構造を適用する]{
//}



==== データ構造作成


ドキュメント構造の値をデータ構造で変更することに利用します。例えば、レイアウトやデザインが同じでも表示されている文言が違ったり、ヘッダー部分の色を変えたりすることができます。他のデザインにする場合はこのJSONファイルの中身を編集するか、GUI画面で編集することも可能ですので、色々試してみましょう。



データ構造JSONファイルURL@<br>{}


//emlist{
http://bit.ly/apl_data_top_json
//}


左のメニューから @<tt>{DATA} をクリックしてコードを貼り付けてください。

//image[s204][データ構造を適用する]{
//}



=== Azure Functions ローカル環境設定


今回はLambdaは使わずにAzure Functionsを使います。すでに環境を用意しているので、GitHubから環境をダウンロードしてください。
まだGit環境がない方は、こちらからインストールしておいてください。

//emlist{
https://git-scm.com/
//}

==== GitHubからプロジェクトを取得する


ローカルの環境にプロジェクトを構築して実際の決済処理の動きを確認してみましょう。
適当なフォルダを作成して、GitHubからクローンしてきます。



Macな方


//emlist{
$ cd ~/Documents
$ git clone https://github.com/gaomar/book-of-alexa-experts-parts.git
//}


Windowsな方


//emlist{
> cd %homepath%\Documents\
> git clone https://github.com/gaomar/book-of-alexa-experts-parts.git
//}

==== Visual Studio Codeに展開する


Visual Studio Codeを開いて、ワークスペースに @<tt>{book-of-alexa-experts-parts} のフォルダを指定します。


ターミナルウィンドウを開いて、下記コマンドを実行します。Macな方は @<tt>{shift + control + @} を Windowsな方は @<tt>{ctrl + @} を押してターミナルウィンドウを開いてください。



下記コマンドを実行してください。

//emlist{
$ pwd
//}

ご自身が居てる階層が、Documentsのbook-of-alexa-experts-partsの直下になっていることを確認してください。

//image[s300-1][book-of-alexa-experts-partsの直下を確認する]{
//}

必要な環境がインストールされますので、下記コマンドを必ず実行してください。

//emlist{
$ npm install
//}


//image[s300][ターミナルウィンドウでコマンドを実行する]{
//}



==== Azure Functions Core Toolをインストール


今回はAzure Functionsを使っておこないますので、Core Toolをインストールします。
下記コマンドを実行してください。


//emlist{
$ npm install -g azure-functions-core-tools
//}

==== ngrokをインストール


トンネリングツールのngrokを使います。まだ未インストールの方は下記コマンドを実行してください。


//emlist{
$ npm install -g ngrok
//}

=== 動作確認


環境が整ったら、いよいよ動作確認してみます。


==== Azure Functionsを起動する


Azure Functionsを起動してローカルで実行できるようにします。下記コマンドを実行してください。


//emlist{
$ func host start
//}


このような表記がでればOKです。


//emlist{
Http Functions:

        uketsuke: [POST] http://localhost:7071/api/uketsuke
//}

==== ngrokを起動する


ターミナルウィンドウで画面分割ボタンをクリックしてから、下記コマンドを実行してください。


//emlist{
$ ngrok http 7071
//}


//image[s301][ngrok実行]{
//}




https側のURLをメモしておきます。このURLはngrokを立ち上げ直すと都度変わりますので注意してください。
URLの有効時間は8時間です。


//emlist{
https://xxxxxxxx.ngrok.io
//}


//image[s302][https側のURLをメモ]{
//}



==== エンドポイントを設定する


alexa developer centerページからエンドポイント設定を行います。
@<tt>{HTTPS} をクリックして、デフォルトの地域に先程メモしたngrokのURLを貼り付けます。


//emlist{
https://xxxxxxxx.ngrok.io/api/uketsuke
//}


プルダウンメニューから「開発用のエンドポイントは、証明機関が発行したワイルドカード証明書をもつドメインのサブドメインです」を選択してください。必ず［エンドポイントを保存］ボタンをクリックします。



//image[s303][エンドポイントを設定]{
//}



==== シミュレーターで確認する


テストタブをクリックして、「開発中」にします。「受付システム」と入力してスキルを開始してください。シミュレーターにデバイスが表示されて、メニューをクリックします。会社名、お名前、人数を答えると受付が完了します。



//image[s304][シミュレーターで確認]{
//}



=== おまけ - LINE Notify通知


最後に来訪者が来たことをLINEに通知する部分を作成します。


==== アクセストークンを取得する


LINE Notifyを実行するためにアクセストークンを取得します。



//emlist{
https://notify-bot.line.me/my/
//}



［トークンを発行する］ボタンをクリックします。



//image[s400][トークンを発行するボタンをクリック]{
//}




トークン名を入力します。今回は「受付システム」としました。トークルームは「1:1でLINE Notifyから通知を受け取る」を選択しました。最後に［発行する］ボタンをクリックします。



//image[s401][トークルームを設定]{
//}




アクセストークンが発行されるのでメモしておきましょう。発行されたトークンは画面を閉じると二度と再発行できません！
//image[s402][トークンをメモ]{
//}



==== プログラムに設定する


取得したアクセストークンをプログラムに反映させます。 @<tt>{.env} ファイルを開いてください。
@<tt>{NOTIFY_TOKEN} 部分に先程取得したトークンを貼り付けて、保存します。



//image[s403][アクセストークンを適用する]{
//}




uketsukeフォルダにある @<tt>{index.js} ファイルを編集します。85行目のコメントアウトを解除してコードを有効にしてください。編集後は保存してください。



//image[s404][85行目のコメントアウトを解除する]{
//}




これで、再度スキルを実行するとLINEに通知が来ます。



//image[s405][LINEに通知]{
//}


== おわりに
このように画面付き対応を簡単に実装することができました。画面付き対応はあくまでも補助的な位置づけで、声の操作がメインです。@<br>{}
VUIでの操作を主として、声だけでは伝えられない情報を画面に付け足すイメージです。APLを使えば簡単に画面付き対応が可能なので、是非チャレンジしてみてください。
